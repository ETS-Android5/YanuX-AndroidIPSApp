{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLE Proximity Experiment - Multi-Layered Perceptron Regressor\n",
    "## Experiment based on the measurements of the BLE RSSI values according to the distance to the BLE Estimote beacon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Imports of required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#CSV Related\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Machine Learning\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import sklearn\n",
    "import scipy\n",
    "\n",
    "#Graphical Display\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine()\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "#Additional Helper Libraries\n",
    "from operator import itemgetter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load File\n",
    "Function that allows to load a file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that reads a csv file and structures the data accordingly\n",
    "def load_file(filename):\n",
    "    dataset = pd.read_csv(filename)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace 0 with Nan RSSI Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_features_nan(dataset):\n",
    "    dataset['rssi_Value'] = dataset['rssi_Value'].replace(0,np.nan)\n",
    "    dataset['rolling_mean_rssi'] = dataset['rolling_mean_rssi'].replace(0,np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataset\n",
    "Initialization of the data from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_file('../../dataset_train_university.csv')\n",
    "positions = dataset['coordinate_Y']\n",
    "dataset['distance'] = positions\n",
    "replace_features_nan(dataset)\n",
    "display(dataset)\n",
    "display(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_file('../../dataset_test_university.csv')\n",
    "positions = test_dataset['coordinate_Y']\n",
    "test_dataset['distance'] = positions\n",
    "replace_features_nan(test_dataset)\n",
    "display(test_dataset)\n",
    "display(test_dataset.shape)\n",
    "test_dataset.hist(bins=50,figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Test Set (HOME | BIG DATASET SAMSUNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_home_big = load_file('../../dataset_test_home_big.csv')\n",
    "positions = test_dataset_home_big['coordinate_Y']\n",
    "test_dataset_home_big['distance'] = positions\n",
    "replace_features_nan(test_dataset_home_big)\n",
    "display(test_dataset_home_big)\n",
    "display(test_dataset_home_big.shape)\n",
    "test_dataset_home_big.hist(bins=50,figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Test Set (HOME | SMALL DATASET SAMSUNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_home_small = load_file('../../dataset_test_home.csv')\n",
    "positions = test_dataset_home_small['coordinate_Y']\n",
    "test_dataset_home_small['distance'] = positions\n",
    "replace_features_nan(test_dataset_home_small)\n",
    "display(test_dataset_home_small)\n",
    "display(test_dataset_home_small.shape)\n",
    "test_dataset_home_small.hist(bins=50,figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Test Set (HOME | SMALL DATASET ASUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_home_asus = load_file('../../dataset_test_home_asus.csv')\n",
    "positions = test_dataset_home_asus['coordinate_Y']\n",
    "test_dataset_home_asus['distance'] = positions\n",
    "replace_features_nan(test_dataset_home_asus)\n",
    "display(test_dataset_home_asus)\n",
    "display(test_dataset_home_asus.shape)\n",
    "test_dataset_home_asus.hist(bins=50,figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Overall Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Overall Description\n",
    "Usage of describe pandas function on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset.describe().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_missing_values(dataset): \n",
    "    missing_values = dataset.isnull().sum()\n",
    "    missing_values_dataset = pd.DataFrame(missing_values,columns=['Missing Values'])\n",
    "    missing_percentage = (dataset.isnull().sum() / dataset.count())\n",
    "    missing_percentage_dataset = pd.DataFrame(missing_percentage,columns=['% of Missing Values'])\n",
    "    missing_dataset = missing_values_dataset.join(missing_percentage_dataset)\n",
    "    display(missing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_missing_values(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Histogram of dataset atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist(bins=50,figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Attribute - Distance\n",
    "Graphical display of the distances beacon/smartphone scanned in the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_points = dataset.groupby(['distance'])\n",
    "reference_points.size().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beacon RSSI Display\n",
    "Graphical display of the rssi values recorded at each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "# Title\n",
    "plt.title('RSSI Probability Distribution')\n",
    "\n",
    "sns.distplot(dataset['rssi_Value'])\n",
    "# The X Label\n",
    "plt.xlabel('RSSI (dB)')\n",
    "# The Y Label\n",
    "plt.ylabel('Probability')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beacon Rolling Mean RSSI Display\n",
    "Graphical adisplay of the rolling mean value recorded at each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "# Title\n",
    "plt.title('RSSI Rolling Mean Probability Distribution')\n",
    "# The KDE plot for the Rolling Mean column\n",
    "sns.distplot(dataset['rolling_mean_rssi'])\n",
    "# The X Label\n",
    "plt.xlabel('RSSI (dB)')\n",
    "# The Y Label\n",
    "plt.ylabel('Probability')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Display of RSSI/Rolling Mean Distribution\n",
    "Graphical display of the previous measures - rssi and rolling mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "# Title\n",
    "plt.title('RSSI Probability Distribution')\n",
    "# The KDE plot for the RSSI column\n",
    "sns.kdeplot(dataset['rssi_Value'], label='RSSI')\n",
    "# The KDE plot for the Rolling Mean column\n",
    "sns.kdeplot(dataset['rolling_mean_rssi'], label='Rolling Mean RSSI')\n",
    "# The X Label\n",
    "plt.xlabel('RSSI (dB)')\n",
    "# The Y Label\n",
    "plt.ylabel('Probability')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "Check how much each attribute collerates with each other. Valures frange from -1 to 1. Close to 1 means a strong positive correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(dataset):\n",
    "    corr_matrix = dataset.corr()\n",
    "    display(corr_matrix)\n",
    "    display(corr_matrix['distance'].sort_values(ascending=False))\n",
    "    attributes = [\"distance\",\"rssi_Value\", \"rolling_mean_rssi\"]\n",
    "    scatter_matrix(dataset[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_correlations(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Fill in missing values and fix/remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_data_cleaning(dataset,feature):\n",
    "    nan_filler = dataset[feature].min()*1.010\n",
    "    dataset[feature] = dataset[feature].fillna(nan_filler) # Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_data_cleaning(dataset,'rssi_Value')\n",
    "compute_data_cleaning(dataset,'rolling_mean_rssi')\n",
    "compute_data_cleaning(test_dataset,'rssi_Value')\n",
    "compute_data_cleaning(test_dataset,'rolling_mean_rssi')\n",
    "compute_data_cleaning(test_dataset_home_big,'rssi_Value')\n",
    "compute_data_cleaning(test_dataset_home_big,'rolling_mean_rssi')\n",
    "compute_data_cleaning(test_dataset_home_small,'rssi_Value')\n",
    "compute_data_cleaning(test_dataset_home_small,'rolling_mean_rssi')\n",
    "compute_data_cleaning(test_dataset_home_asus,'rssi_Value')\n",
    "compute_data_cleaning(test_dataset_home_asus,'rolling_mean_rssi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Categorical Data\n",
    "Using Hot-Encoder or Label Encoder to convert text/categorical data into numerical data. ML algorithms prefer it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "def compute_encoder(categorical_data,flag):\n",
    "    if flag == 0:\n",
    "        labels = label_encoder.fit_transform(categorical_data)\n",
    "    else:\n",
    "        labels = label_encoder.transform(categorical_data)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_zone = dataset[['zone']]\n",
    "print(\"Previous Categorical Data\")\n",
    "display(categorical_zone)\n",
    "zone_changed = compute_encoder(categorical_zone,0)\n",
    "print(\"After One Hot Encoder\")\n",
    "dataset['labels'] = zone_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_zone = test_dataset[['zone']]\n",
    "print(\"Previous Categorical Data\")\n",
    "display(categorical_zone)\n",
    "test_changed = compute_encoder(categorical_zone,1)\n",
    "print(\"After One Hot Encoder\")\n",
    "test_dataset['labels'] = test_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_zone = test_dataset_home_big[['zone']]\n",
    "print(\"Previous Categorical Data\")\n",
    "display(categorical_zone)\n",
    "test_changed = compute_encoder(categorical_zone,1)\n",
    "print(\"After One Hot Encoder\")\n",
    "test_dataset_home_big['labels'] = test_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_zone = test_dataset_home_small[['zone']]\n",
    "print(\"Previous Categorical Data\")\n",
    "display(categorical_zone)\n",
    "test_changed = compute_encoder(categorical_zone,1)\n",
    "print(\"After One Hot Encoder\")\n",
    "test_dataset_home_small['labels'] = test_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_zone = test_dataset_home_asus[['zone']]\n",
    "print(\"Previous Categorical Data\")\n",
    "display(categorical_zone)\n",
    "test_changed = compute_encoder(categorical_zone,1)\n",
    "print(\"After One Hot Encoder\")\n",
    "test_dataset_home_asus['labels'] = test_changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training Data\n",
    "Training Data intialization for predictions purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_rssi = pd.DataFrame(dataset['rssi_Value']).values.reshape(-1,1)\n",
    "display(train_X_rssi.shape)\n",
    "train_X_rolling_mean = pd.DataFrame(dataset['rolling_mean_rssi']).values.reshape(-1,1)\n",
    "display(train_X_rolling_mean.shape)\n",
    "combination_features_X = dataset[['rssi_Value','rolling_mean_rssi']]\n",
    "display(combination_features_X.shape)\n",
    "default_groups = dataset['labels'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = pd.DataFrame(dataset['distance']).values.reshape(-1,1)\n",
    "display(train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot_means = dataset.groupby(['distance'])[['rssi_Value','rolling_mean_rssi']].mean()\n",
    "display(data_plot_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Training Data\n",
    "Graphical Display of the observations in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.scatter(dataset['distance'],dataset['rssi_Value'],label='RSSI Value',color='blue')\n",
    "plt.scatter(dataset['distance'],dataset['rolling_mean_rssi'],label='Rolling Mean RSSI Value',color='orange')\n",
    "plt.title('Observations')  \n",
    "plt.xlabel('Zone')  \n",
    "plt.ylabel('RSSI(dB)')  \n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_rssi = pd.DataFrame(test_dataset['rssi_Value']).values.reshape(-1,1)\n",
    "display(test_X_rssi.shape)\n",
    "test_X_rolling_mean = pd.DataFrame(test_dataset['rolling_mean_rssi']).values.reshape(-1,1)\n",
    "display(test_X_rolling_mean.shape)\n",
    "test_combination_features_X = test_dataset[['rssi_Value','rolling_mean_rssi']]\n",
    "display(test_combination_features_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y = pd.DataFrame(test_dataset['distance']).values.reshape(-1,1)\n",
    "display(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot_means = test_dataset.groupby(['distance'])[['rssi_Value','rolling_mean_rssi']].mean()\n",
    "display(data_plot_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_rssi_home_big = pd.DataFrame(test_dataset_home_big['rssi_Value']).values.reshape(-1,1)\n",
    "display(test_X_rssi_home_big.shape)\n",
    "test_X_rolling_mean_home_big = pd.DataFrame(test_dataset_home_big['rolling_mean_rssi']).values.reshape(-1,1)\n",
    "display(test_X_rolling_mean_home_big.shape)\n",
    "test_combination_features_X_home_big = test_dataset_home_big[['rssi_Value','rolling_mean_rssi']]\n",
    "display(test_combination_features_X_home_big.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_home_big = pd.DataFrame(test_dataset_home_big['distance']).values.reshape(-1,1)\n",
    "display(test_Y_home_big .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot_means = test_dataset_home_big.groupby(['zone'])[['rssi_Value','rolling_mean_rssi']].mean()\n",
    "display(data_plot_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_rssi_home_small = pd.DataFrame(test_dataset_home_small['rssi_Value']).values.reshape(-1,1)\n",
    "display(test_X_rssi_home_small.shape)\n",
    "test_X_rolling_mean_home_small = pd.DataFrame(test_dataset_home_small['rolling_mean_rssi']).values.reshape(-1,1)\n",
    "display(test_X_rolling_mean_home_small.shape)\n",
    "test_combination_features_X_home_small = test_dataset_home_small[['rssi_Value','rolling_mean_rssi']]\n",
    "display(test_combination_features_X_home_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_home_small = pd.DataFrame(test_dataset_home_small['distance']).values.reshape(-1,1)\n",
    "display(test_Y_home_small .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot_means = test_dataset_home_small.groupby(['zone'])[['rssi_Value','rolling_mean_rssi']].mean()\n",
    "display(data_plot_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_rssi_home_asus = pd.DataFrame(test_dataset_home_asus['rssi_Value']).values.reshape(-1,1)\n",
    "display(test_X_rssi_home_asus.shape)\n",
    "test_X_rolling_mean_home_asus = pd.DataFrame(test_dataset_home_asus['rolling_mean_rssi']).values.reshape(-1,1)\n",
    "display(test_X_rolling_mean_home_asus.shape)\n",
    "test_combination_features_X_home_asus = test_dataset_home_asus[['rssi_Value','rolling_mean_rssi']]\n",
    "display(test_combination_features_X_home_asus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_home_asus = pd.DataFrame(test_dataset_home_asus['distance']).values.reshape(-1,1)\n",
    "display(test_Y_home_small .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot_means = test_dataset_home_asus.groupby(['zone'])[['rssi_Value','rolling_mean_rssi']].mean()\n",
    "display(data_plot_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.scatter(test_dataset['distance'],test_dataset['rssi_Value'],label='Test RSSI Value',color='blue')\n",
    "plt.scatter(test_dataset['distance'],test_dataset['rolling_mean_rssi'],label='Test Rolling Mean RSSI Value',color='orange')\n",
    "plt.title('Observations')  \n",
    "plt.xlabel('Zone')  \n",
    "plt.ylabel('RSSI(dB)')  \n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.scatter(test_dataset_home_big['distance'],test_dataset_home_big['rssi_Value'],label='Test SAMSUNG RSSI Value',color='blue')\n",
    "plt.scatter(test_dataset_home_big['distance'],test_dataset_home_big['rolling_mean_rssi'],label='Test SAMSUNG Rolling Mean RSSI Value',color='orange')\n",
    "plt.title('Observations')  \n",
    "plt.xlabel('Zone')  \n",
    "plt.ylabel('RSSI(dB)')  \n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.scatter(test_dataset_home_small['distance'],test_dataset_home_small['rssi_Value'],label='Test SAMSUNG RSSI Value',color='blue')\n",
    "plt.scatter(test_dataset_home_small['distance'],test_dataset_home_small['rolling_mean_rssi'],label='Test SAMSUNG Rolling Mean RSSI Value',color='orange')\n",
    "plt.title('Observations')  \n",
    "plt.xlabel('Zone')  \n",
    "plt.ylabel('RSSI(dB)')  \n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.scatter(test_dataset_home_asus['distance'],test_dataset_home_asus['rssi_Value'],label='Test ASUS RSSI Value',color='blue')\n",
    "plt.scatter(test_dataset_home_asus['distance'],test_dataset_home_asus['rolling_mean_rssi'],label='Test ASUS Rolling Mean RSSI Value',color='orange')\n",
    "plt.title('Observations')  \n",
    "plt.xlabel('Zone')  \n",
    "plt.ylabel('RSSI(dB)')  \n",
    "plt.legend(loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Hyperparameters for tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing options\n",
    "scaler = [StandardScaler(),MaxAbsScaler(),MinMaxScaler(),None]\n",
    "# Batch size of samples\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# Epochs \n",
    "epochs = [10, 50, 100]\n",
    "# Optimization function\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "# Learning Rate - only used with SGD optimizer\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "# Momentum - only used with SGD optimizer\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "# Activation Function\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "# Number of neurons in a hidden layer\n",
    "neurons = [100,300,400,500,600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics Output Format\n",
    "Structure of the statistical output of each call to the machine learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_data(data,rsquared):\n",
    "    mae = data['error'].abs().mean()\n",
    "    mse = np.power(data['error'],2).mean()\n",
    "    rsme = np.sqrt(mse)\n",
    "    std = data['error'].std()\n",
    "    q25 = data['error'].quantile(q=0.25)\n",
    "    q50= data['error'].quantile(q=0.5)\n",
    "    q75 =data['error'].quantile(q=0.7)\n",
    "    q95= data['error'].quantile(q=0.95)\n",
    "    r_squared = rsquared\n",
    "    minValue= data['error'].min()\n",
    "    maxValue = data['error'].max()\n",
    "    statistical_results = [mae,mse,rsme,std,q25,q50,q75,q95,minValue,maxValue,r_squared]\n",
    "    return statistical_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "Check strength of features using ensemble algorithm Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Selection Computation\")\n",
    "random_forest_estimator = RandomForestRegressor()\n",
    "main_estimator = make_pipeline(StandardScaler(),random_forest_estimator)\n",
    "main_estimator.fit(combination_features_X,train_Y.ravel())\n",
    "display(random_forest_estimator.feature_importances_)\n",
    "feature_imp = pd.Series(random_forest_estimator.feature_importances_,index=combination_features_X.columns).sort_values(ascending=False)\n",
    "display(feature_imp)\n",
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation - MLP Regression Model\n",
    "Experiments with MLP algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons_basic = 180\n",
    "print(\"Default number of neurons: \" + str(num_neurons_basic))\n",
    "# Function to create model, required for KerasRegressor\n",
    "def create_model(dim=2,num_neurons=num_neurons_basic,activation ='relu',optimizer = 'adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons,input_dim=dim,activation=activation))\n",
    "    model.add(Dense(num_neurons,activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer,metrics=['accuracy','mean_absolute_error'])\n",
    "    return model\n",
    "model = create_model()\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_MLP_Regressor(flag=0,dim=2,\n",
    "                              trainX_data = None, trainY_data = None,\n",
    "                              testX_data = None,testY_data = None, \n",
    "                              scaler = None,cross_validation = None,batch_size=10,epochs=50,verbose=0,num_neurons_param=180,\n",
    "                          optimizer_func='adam',activation_func='relu'):\n",
    "    keras_regressor = KerasRegressor(build_fn=create_model,dim=dim,epochs=epochs,num_neurons=num_neurons_param,\n",
    "                                     optimizer=optimizer_func,activation=activation_func,batch_size=batch_size,verbose=verbose)\n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    if scaler is not None:\n",
    "        # Make pipeline using scaler transformation\n",
    "        main_estimator = make_pipeline(scaler,keras_regressor)\n",
    "    else:\n",
    "        main_estimator = keras_regressor\n",
    "    if cross_validation is None:\n",
    "        # Fit the training data\n",
    "        main_estimator.fit(trainX_data,trainY_data)\n",
    "        # Predict the results of the testing data features\n",
    "        predict_test = main_estimator.predict(testX_data)\n",
    "        coefficient_determination = sklearn.metrics.r2_score(testY_data,predict_test)\n",
    "    else:\n",
    "        print(\"Cross Validation Activated. CV = \" + str(cross_validation))\n",
    "        predict_test = cross_val_predict(main_estimator,testX_data,testY_data,cv = cross_validation,groups=default_groups)\n",
    "        coefficient_determination = sklearn.metrics.r2_score(testY_data,predict_test)\n",
    "    statistical_array = list()\n",
    "    error_dataframe = pd.DataFrame({'Actual': testY_data.flatten(), 'Predicted':predict_test.flatten()})\n",
    "    if flag == 1:\n",
    "        display(error_dataframe)\n",
    "        error_dataframe.apply(pd.value_counts).plot(kind='bar', subplots=True)\n",
    "    observed_errors = error_dataframe['Predicted'] - error_dataframe['Actual']\n",
    "    error = pd.DataFrame(observed_errors, columns=[\"error\"])\n",
    "    result = pd.DataFrame(train_Y,columns=[\"distance\"]).join(error)\n",
    "    return structure_data(result,coefficient_determination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Training model with no cross validation\n",
    "Use MLP Regressor to check the results on the training data alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_cols = ['mae','mse','rmse','std','.25','0.5','0.75','0.95','min','max','r-squared','type']\n",
    "types = ['RSSI Only','Rolling Mean RSSI','Both']\n",
    "results = list()\n",
    "for feature in types:\n",
    "    if feature == 'RSSI Only':\n",
    "        trainX_data = train_X_rssi\n",
    "        dim = 1\n",
    "    elif feature == 'Rolling Mean RSSI':\n",
    "        trainX_data = train_X_rolling_mean\n",
    "        dim =1\n",
    "    else:\n",
    "        trainX_data = combination_features_X \n",
    "        dim = 2\n",
    "    result = compute_MLP_Regressor(flag=1,dim=dim,trainX_data=trainX_data,trainY_data=train_Y,\n",
    "                                   testX_data=trainX_data,testY_data=train_Y,\n",
    "                                   scaler=StandardScaler())\n",
    "    result.append(feature)\n",
    "    results.append(result)\n",
    "statistics = pd.DataFrame(columns=statistical_cols,data=results)\n",
    "display(statistics.sort_values(by=['mae']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment - Validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(dim=2)\n",
    "history = model.fit(combination_features_X,train_Y,validation_split=0.3,batch_size = 10,epochs=50,verbose=1)\n",
    "plt.figure(figsize=(12,6))\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "model.evaluate(combination_features_X,train_Y,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment -MLP with Stratified K-Fold\n",
    "Experiment using cross validation approach of StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_cols = ['mae','mse','rmse','std','.25','0.5','0.75','0.95','min','max','r-squared','folds','type']\n",
    "types = ['RSSI Only','Rolling Mean RSSI','Both']\n",
    "cross_validation_list = np.arange(2,6)\n",
    "results = list()\n",
    "for feature in types:\n",
    "    #Decide on type of data\n",
    "    if feature == 'RSSI Only':\n",
    "        trainX_data = train_X_rssi\n",
    "        dim = 1\n",
    "    elif feature == 'Rolling Mean RSSI':\n",
    "        trainX_data = train_X_rolling_mean\n",
    "        dim = 1\n",
    "    else:\n",
    "        trainX_data = combination_features_X \n",
    "        dim = 2\n",
    "    for cv in cross_validation_list:\n",
    "        skf = StratifiedKFold(n_splits=cv)\n",
    "        splited = skf.split(trainX_data,default_groups)\n",
    "        result = compute_MLP_Regressor(testX_data=trainX_data,dim=dim,testY_data=train_Y.ravel(),epochs=25,\n",
    "                                   scaler=StandardScaler(),cross_validation=splited)\n",
    "        result.append(cv)\n",
    "        result.append(feature)\n",
    "        results.append(result)\n",
    "statistics = pd.DataFrame(columns=statistical_cols,data=results)\n",
    "display(statistics.sort_values(by=['mae']))\n",
    "selected_fold = statistics.sort_values(by=['mae'])['folds'].head(1).values[0]\n",
    "print(\"Number of Folds: \",selected_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment - MLP with HoldOut\n",
    "Experiment using cross validation approach of HoldOut (Train test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_cols = ['mae','mse','rmse','std','.25','0.5','0.75','0.95','min','max','r-squared','test_size','type']\n",
    "test_sizes =[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "results = list()\n",
    "types = ['RSSI Only','Rolling Mean RSSI','Both']\n",
    "for feature in types:\n",
    "    #Decide on type of data\n",
    "    if feature == 'RSSI Only':\n",
    "        trainX_data = train_X_rssi\n",
    "        dim =1\n",
    "    elif feature == 'Rolling Mean RSSI':\n",
    "        trainX_data = train_X_rolling_mean\n",
    "        dim = 1\n",
    "    else:\n",
    "        trainX_data = combination_features_X\n",
    "        dim = 2\n",
    "    for size in test_sizes:\n",
    "        X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(trainX_data,train_Y, test_size = size, random_state = 42,stratify=default_groups)\n",
    "        result = compute_MLP_Regressor(dim=dim,epochs=25,trainX_data=X_train_split,trainY_data=y_train_split,testX_data=X_test_split,testY_data=y_test_split,\n",
    "                                       scaler=StandardScaler())\n",
    "        result.append(size)\n",
    "        result.append(feature)\n",
    "        results.append(result)\n",
    "statistics = pd.DataFrame(columns=statistical_cols,data=results)\n",
    "display(statistics.sort_values(by=['mae']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment - MLP with Leave One Group Out\n",
    "Experiment using cross validation approach of Leave One Group Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_cols = ['mae','mse','rmse','std','.25','0.5','0.75','0.95','min','max','r-squared','type']\n",
    "results = list()\n",
    "types = ['RSSI Only','Rolling Mean RSSI','Both']\n",
    "for feature in types:\n",
    "    #Decide on type of data\n",
    "    if feature == 'RSSI Only':\n",
    "        trainX_data = train_X_rssi\n",
    "        dim = 1\n",
    "    elif feature == 'Rolling Mean RSSI':\n",
    "        trainX_data = train_X_rolling_mean\n",
    "        dim = 1\n",
    "    else:\n",
    "        trainX_data = combination_features_X\n",
    "        dim = 2\n",
    "    cv = LeaveOneGroupOut()\n",
    "    splited = cv.split(trainX_data,train_Y,groups=default_groups.ravel())\n",
    "    result = compute_MLP_Regressor(testX_data=trainX_data,testY_data=train_Y,dim=dim,epochs=25,scaler=StandardScaler(),cross_validation = splited)\n",
    "    result.append(feature)\n",
    "    results.append(result)\n",
    "statistics = pd.DataFrame(columns=statistical_cols,data=results)\n",
    "display(statistics.sort_values(by=['mae']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Model Cross-Validation Experiment - Best cross-validation technique\n",
    "Best parameters found using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_cols = ['mae','mse','rmse','std','.25','0.5','0.75','0.95','min','max','r-squared','method','type']\n",
    "types = ['RSSI Only','Rolling Mean RSSI','Both']\n",
    "results = list()\n",
    "for feature in types:\n",
    "    #Decide on type of data\n",
    "    if feature == 'RSSI Only':\n",
    "        trainX_data = train_X_rssi\n",
    "        dim = 1\n",
    "    elif feature == 'Rolling Mean RSSI':\n",
    "        trainX_data = train_X_rolling_mean\n",
    "        dim = 1\n",
    "    else:\n",
    "        trainX_data = combination_features_X\n",
    "        dim = 2\n",
    "    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(trainX_data,train_Y, test_size = 0.3, random_state = 42,stratify=default_groups)\n",
    "    holdout = compute_MLP_Regressor(verbose=1,dim=dim,epochs=25,trainX_data=X_train_split,trainY_data=y_train_split,testX_data=X_test_split,testY_data=y_test_split,scaler=StandardScaler())\n",
    "    cv = LeaveOneGroupOut()\n",
    "    splited = cv.split(trainX_data,train_Y,groups=default_groups.ravel())\n",
    "    loo = compute_MLP_Regressor(testX_data=trainX_data,dim=dim,epochs=25,testY_data=train_Y,scaler=StandardScaler(),cross_validation = splited)  \n",
    "    loo.append('LOO')\n",
    "    loo.append(feature)\n",
    "    results.append(loo)\n",
    "    holdout.append('HoldOut')\n",
    "    holdout.append(feature)\n",
    "    results.append(holdout)\n",
    "    skf = StratifiedKFold(n_splits=selected_fold)\n",
    "    splited = skf.split(trainX_data,default_groups)\n",
    "    skfold = compute_MLP_Regressor(testX_data=trainX_data,dim=dim,epochs=25,testY_data=train_Y,scaler=StandardScaler(),cross_validation = splited)  \n",
    "    skfold.append('Stratified K-Fold')\n",
    "    skfold.append(feature)\n",
    "    results.append(skfold)\n",
    "statistics = pd.DataFrame(columns=statistical_cols,data=results)\n",
    "display(statistics.sort_values(by=['mae']))\n",
    "selected_method = statistics.sort_values(by=['mae'])['method'].head(1).values[0]\n",
    "print(\"Selected cross validation method: \",selected_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment - Best preprocessing technique\n",
    "Experiment with the different preprocessing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_cols = ['mae','mse','rmse','std','.25','0.5','0.75','0.95','min','max','r-squared','preprocessing','preprocessingFunc','type']\n",
    "types = ['RSSI Only','Rolling Mean RSSI','Both']\n",
    "results = list()\n",
    "dim = 2\n",
    "for scannedType in types:\n",
    "    if scannedType == 'RSSI Only':\n",
    "        trainX_data = train_X_rssi\n",
    "        dim = 1\n",
    "    elif scannedType == 'Rolling Mean RSSI':\n",
    "        trainX_data = train_X_rolling_mean\n",
    "        dim = 1\n",
    "    else:\n",
    "        trainX_data = combination_features_X\n",
    "        dim = 2\n",
    "    for preprocess in scaler:\n",
    "        if selected_method == 'LOO':\n",
    "            cv = LeaveOneGroupOut()\n",
    "            splited = cv.split(train_X_rssi,train_Y,groups=default_groups)\n",
    "            loo = compute_MLP_Regressor(flag = 0,testX_data=trainX_data,dim=dim,epochs=25,testY_data=train_Y,scaler=StandardScaler(),cross_validation = splited) \n",
    "        elif selected_method =='Stratified K-Fold':\n",
    "            skf = StratifiedKFold(n_splits=cv)\n",
    "            splited = skf.split(train_X_rssi,default_groups,default_groups)\n",
    "            result = compute_MLP_Regressor(flag = 0,testX_data=trainX_data,dim=dim,epochs=25,testY_data=train_Y,scaler=StandardScaler(),cross_validation = selected_fold)  \n",
    "        else:\n",
    "            X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(trainX_data,train_Y, test_size = 0.4, random_state = 6,stratify=default_groups)\n",
    "            result = compute_MLP_Regressor(dim=dim,epochs=25,trainX_data=X_train_split,trainY_data=y_train_split,testX_data=X_test_split,testY_data=y_test_split,scaler=StandardScaler())\n",
    "        if(preprocess is None):\n",
    "            regex = 'None'\n",
    "        else:\n",
    "            regex = re.search('(\\w+)\\(',str(preprocess)).group(1)\n",
    "        result.append(regex)\n",
    "        result.append(preprocess)\n",
    "        result.append(scannedType)\n",
    "        results.append(result)\n",
    "statistics = pd.DataFrame(columns=statistical_cols,data=results)\n",
    "display(statistics.sort_values(by=['mae']))\n",
    "plt.plot(statistics['preprocessing'],statistics['mae'])\n",
    "selected_preprocessing = statistics.sort_values(by=['mae'])['preprocessing'].head(1).values[0]\n",
    "selected_preprocesssing_func = statistics.sort_values(by=['mae'])['preprocessingFunc'].head(1).values[0]\n",
    "print(\"Selected Preprocessing: \",selected_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run RandomSearchCV for parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'neg_mean_absolute_error'\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X_rolling_mean)\n",
    "tr = scaler.transform(train_X_rolling_mean)\n",
    "model = KerasRegressor(build_fn=create_model,dim=1,epochs=50,batch_size=10,verbose=0)\n",
    "param_grid = dict(activation=activation,optimizer=optimizer,num_neurons=neurons)\n",
    "grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n",
    "                          cv=StratifiedKFold(n_splits=4, shuffle=True, random_state=6).split(trainX_data,default_groups,default_groups),\n",
    "                          scoring=score,random_state=42)\n",
    "display(grid)\n",
    "grid_result = grid.fit(tr.reshape(-1,1), train_Y.reshape(-1,1))\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Results\n",
    "Compute MLP with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistical_cols = ['mae','mse','rmse','std','.25','0.5','0.75','0.95','min','max','r-squared','type']\n",
    "types = ['RSSI Only','Rolling Mean RSSI','Both']\n",
    "results = list()\n",
    "dim = 2\n",
    "selected_method = 'HoldOut'\n",
    "for scannedType in types:\n",
    "    if scannedType == 'RSSI Only':\n",
    "        trainX_data = train_X_rssi\n",
    "        dim = 1\n",
    "    elif scannedType == 'Rolling Mean RSSI':\n",
    "        trainX_data = train_X_rolling_mean\n",
    "        dim = 1\n",
    "    else:\n",
    "        trainX_data = combination_features_X\n",
    "        dim = 2\n",
    "    if selected_method == 'LOO':\n",
    "        cv = LeaveOneGroupOut()\n",
    "        splited = cv.split(train_X_rssi,train_Y,groups=default_groups)\n",
    "        loo = compute_MLP_Regressor(flag = 0,verbose=1,testX_data=trainX_data,dim=dim,epochs=25,testY_data=train_Y,scaler=StandardScaler(),cross_validation = splited) \n",
    "    elif selected_method =='Stratified K-Fold':\n",
    "        skf = StratifiedKFold(n_splits=cv)\n",
    "        splited = skf.split(train_X_rssi,default_groups,default_groups)\n",
    "        result = compute_MLP_Regressor(flag = 0,verbose=1,testX_data=trainX_data,dim=dim,epochs=25,testY_data=train_Y,scaler=StandardScaler(),cross_validation = selected_fold)  \n",
    "    else:\n",
    "        X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(trainX_data,train_Y, test_size = 0.4, random_state = 6,stratify=default_groups)\n",
    "        result = compute_MLP_Regressor(dim=dim,epochs=25,verbose=1,trainX_data=X_train_split,trainY_data=y_train_split,testX_data=X_test_split,testY_data=y_test_split,scaler=StandardScaler())\n",
    "    result.append(scannedType)\n",
    "    results.append(result)\n",
    "statistics = pd.DataFrame(columns=statistical_cols,data=results)\n",
    "display(statistics.sort_values(by=['mae']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
